{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "bzcat = pd.read_excel('../data/bzcat_full.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the data are collected directly into a Pandas dataframe. This is because the FIRST, 2MASS, and WISE data may appear in the response or not. A 'defaultdict' construction might work faster, but the code will be more bulky with it. The runtime is of second concern here as we anyway have limitations in requests per minute (time sleep = 1s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(columns=['Source name', 'SDSS id', 'u', 'u_err', 'g',\n",
    "    'g_err', 'r', 'r_err', 'i', 'i_err', 'z', 'z_err', 'extinction_r', 'J', \n",
    "    'H', 'K', 'w1', 'w2', 'w3', 'w4', 'FIRST'])\n",
    "\n",
    "j, n = 0, bzcat.shape[0]\n",
    "bzcat.reset_index(inplace=True)\n",
    "\n",
    "for index, obj in bzcat.iterrows():\n",
    "    j += 1\n",
    "    print(f'Processing {j} out of {n}')\n",
    "    result_dict = {'Source name': obj['BZCAT5 Source name']}\n",
    "    \n",
    "    url = 'http://skyserver.sdss.org/dr17/en/tools/explore/Summary.aspx?ra=' \\\n",
    "        + obj['RA (J2000.0)'] + '&dec=' + obj['Dec (J2000.0)']\n",
    "    response = requests.get(url)\n",
    "    page = BeautifulSoup(response.text, 'html.parser') \n",
    "    tds = page.find_all('td')\n",
    "    \n",
    "    if len(tds) > 0:\n",
    "        result_dict.update({\n",
    "            'SDSS id': tds[6].text, 'u': tds[11].text, 'g': tds[12].text,\n",
    "            'r': tds[13].text, 'i': tds[14].text, 'z': tds[15].text, 'u_err':\n",
    "            tds[16].text, 'g_err': tds[17].text, 'r_err': tds[18].text, \n",
    "            'i_err': tds[19].text, 'z_err': tds[20].text, 'extinction_r': \n",
    "            tds[26].text\n",
    "        })  \n",
    "        for i in range(31, len(tds)):\n",
    "            if tds[i].text == 'FIRST':\n",
    "                result_dict.update({'FIRST': tds[i+1].text})\n",
    "            if tds[i].text == '2MASS':\n",
    "                result_dict.update({'J': tds[i+1].text, 'H': tds[i+2].text,\n",
    "                                    'K': tds[i+3].text})\n",
    "            if tds[i].text == 'WISE':\n",
    "                result_dict.update({'w1': tds[i+1].text, 'w2': tds[i+2].text,\n",
    "                                    'w3': tds[i+3].text, 'w4': tds[i+4].text})\n",
    "    \n",
    "    result_df = pd.concat(\n",
    "        [result_df, pd.DataFrame(result_dict, index=[0])], ignore_index=True)\n",
    "    time.sleep(1)   \n",
    "   \n",
    "result_df.to_csv('../data/SDSS_data.xlsx')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
